{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This is review on the MongoDB Atlas Search\n",
    "\n",
    "* What is \"MongoDB Atlas Search\": Is a way to search a text **quyickly**. The seach is relying on pre-existing  \"MongoDB Atlas Search Index\" (pre-built index that apply MongoDB to retrieve the required results more quickly).\n",
    "\n",
    "##### After this tutotrial you will be able:\n",
    "    1. Understanging what is seach index.\n",
    "    2. Know what is \"MongoDB Atlas Search\" and his capabilities.\n",
    "    3. Anayze the effectiveness of a query.\n",
    "    4. Easily connect to MongoDB and be able to run all wanted queries(without the limitations of driver).\n",
    "\n",
    "* This notebooks contains 3 parts:\n",
    "    1. Look at example for the efficiency of indexing.\n",
    "    2. Look at the capabilities of it, when indexing a textual field\n",
    "    3. How to connect to MongoDB through HTTP\n",
    "\n",
    "\\*In order to run this notebook interactively, please go to \"part 3\" first, to set up the connection."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from helper import *\n",
    "from queries import *\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "from config_file import *\n",
    "from pymongo import MongoClient\n",
    "from create_db import  db_creation\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from indices.index1 import create_index1\n",
    "from indices.index2 import create_index2\n",
    "from indices.index3 import create_index3\n",
    "\n",
    "client = MongoClient(CONN_STRING)\n",
    "mydb = client[DB_NAME]\n",
    "collection = mydb[COLLECTION_NAME]\n",
    "\n",
    "ps = PorterStemmer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1 - Efficiency of indexing.\n",
    "\n",
    "We will be using the sample dataset available with MongoDB Atlas clusters.\n",
    "\n",
    "* Each database contains collections and each collection contains documnts(the actual records).\n",
    "* Every MongoDB collection has a default index: \"_id\". This is created during the creation of the collection, every documnet created with unique \"_id\" and this index can not be deleted."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# connecting to the collection\n",
    "client = MongoClient(CONN_STRING)\n",
    "mydb = client[\"sample_restaurants\"]\n",
    "collection = mydb[\"restaurants\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Existing index information"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "outputs": [
    {
     "data": {
      "text/plain": "{'_id': ObjectId('5eb3d668b31de5d588f4292a'),\n 'address': {'building': '2780',\n  'coord': [-73.98241999999999, 40.579505],\n  'street': 'Stillwell Avenue',\n  'zipcode': '11224'},\n 'borough': 'Brooklyn',\n 'cuisine': 'American',\n 'grades': [{'date': datetime.datetime(2014, 6, 10, 0, 0),\n   'grade': 'A',\n   'score': 5},\n  {'date': datetime.datetime(2013, 6, 5, 0, 0), 'grade': 'A', 'score': 7},\n  {'date': datetime.datetime(2012, 4, 13, 0, 0), 'grade': 'A', 'score': 12},\n  {'date': datetime.datetime(2011, 10, 12, 0, 0), 'grade': 'A', 'score': 12}],\n 'name': 'Riviera Caterer',\n 'restaurant_id': '40356018'}"
     },
     "execution_count": 1224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of document in the database\n",
    "collection.find_one()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "outputs": [
    {
     "data": {
      "text/plain": "{'_id_': {'v': 2, 'key': [('_id', 1)]}}"
     },
     "execution_count": 1226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The default index\n",
    "collection.index_information()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Let's check how many records there are in total and how many for a specific query which: cuisine=American"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total of 25359 documents and for cuisine=American thare are: 6183 documents\n"
     ]
    }
   ],
   "source": [
    "total_records = collection.count_documents({})\n",
    "specific_records = collection.count_documents({'cuisine':'American'})\n",
    "print(f'There are total of {total_records} documents and for cuisine=American thare are: {specific_records} documents.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Now that we know the amount of documents in the Lets dive deeper to understand the power of indexing\n",
    "\n",
    "When we run a query in MongoDB, we can actually determine a lot of information about the query using the \"explain()\" function.\n",
    "It returns a document that contains information about the query plans and the execution statistics.\n",
    "\n",
    "Here, focus on the executionStats key which contains the execution statistics. Below are the important keys to focus on:[1]\n",
    "\n",
    "* *explain.executionStats.nReturned* - returns the number of documents that match the query\n",
    "* *explain.executionStats.executionTimeMillis* - returns the total time in milliseconds required for query plan selection and query execution\n",
    "* *explain.executionStats.totalKeysExamined* - returns the number of index entries scanned\n",
    "* *eplain.executionStats.totalDocsExamined* - returns the number of documents examined during query execution. These are not documents that are returned\n",
    "* *executionStats.executionStages.stage* - COLLSCAN/IXSCAN\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'allPlansExecution': [],\n",
      " 'executionStages': {'advanced': 6183,\n",
      "                     'direction': 'forward',\n",
      "                     'docsExamined': 25359,\n",
      "                     'executionTimeMillisEstimate': 1,\n",
      "                     'filter': {'cuisine': {'$eq': 'American'}},\n",
      "                     'isEOF': 1,\n",
      "                     'nReturned': 6183,\n",
      "                     'needTime': 19177,\n",
      "                     'needYield': 0,\n",
      "                     'restoreState': 25,\n",
      "                     'saveState': 25,\n",
      "                     'stage': 'COLLSCAN',\n",
      "                     'works': 25361},\n",
      " 'executionSuccess': True,\n",
      " 'executionTimeMillis': 12,\n",
      " 'nReturned': 6183,\n",
      " 'totalDocsExamined': 25359,\n",
      " 'totalKeysExamined': 0}\n"
     ]
    }
   ],
   "source": [
    "pprint(collection.find({'cuisine':'American'}).explain()['executionStats'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "we can notice that when we want to find all \"cuisine\"=\"American\" in couple of things:\n",
    "1. we are going over all the documents in the collection!(\"totalDocsExamined\" = 25359).\n",
    "2. The retuned documents are as we expected('nReturned': 6183).\n",
    "3. 'stage': 'COLLSCAN' -  It means that the default \"_id\" index was used to scan all the collection.\n",
    "4. The execution time is 12 miliseconds.\n",
    "\n",
    "##### Now lets create an index and examine the same results again"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 2 indices: {'_id_': {'v': 2, 'key': [('_id', 1)]}, 'cuisine_1': {'v': 2, 'key': [('cuisine', 1)]}}\n"
     ]
    }
   ],
   "source": [
    "# Create new index\n",
    "collection.create_index('cuisine')\n",
    "\n",
    "print(f\"There are now 2 indices: {collection.index_information()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'allPlansExecution': [],\n",
      " 'executionStages': {'advanced': 6183,\n",
      "                     'alreadyHasObj': 0,\n",
      "                     'docsExamined': 6183,\n",
      "                     'executionTimeMillisEstimate': 1,\n",
      "                     'inputStage': {'advanced': 6183,\n",
      "                                    'direction': 'forward',\n",
      "                                    'dupsDropped': 0,\n",
      "                                    'dupsTested': 0,\n",
      "                                    'executionTimeMillisEstimate': 0,\n",
      "                                    'indexBounds': {'cuisine': ['[\"American\", '\n",
      "                                                                '\"American\"]']},\n",
      "                                    'indexName': 'cuisine_1',\n",
      "                                    'indexVersion': 2,\n",
      "                                    'isEOF': 1,\n",
      "                                    'isMultiKey': False,\n",
      "                                    'isPartial': False,\n",
      "                                    'isSparse': False,\n",
      "                                    'isUnique': False,\n",
      "                                    'keyPattern': {'cuisine': 1},\n",
      "                                    'keysExamined': 6183,\n",
      "                                    'multiKeyPaths': {'cuisine': []},\n",
      "                                    'nReturned': 6183,\n",
      "                                    'needTime': 0,\n",
      "                                    'needYield': 0,\n",
      "                                    'restoreState': 6,\n",
      "                                    'saveState': 6,\n",
      "                                    'seeks': 1,\n",
      "                                    'stage': 'IXSCAN',\n",
      "                                    'works': 6184},\n",
      "                     'isEOF': 1,\n",
      "                     'nReturned': 6183,\n",
      "                     'needTime': 0,\n",
      "                     'needYield': 0,\n",
      "                     'restoreState': 6,\n",
      "                     'saveState': 6,\n",
      "                     'stage': 'FETCH',\n",
      "                     'works': 6184},\n",
      " 'executionSuccess': True,\n",
      " 'executionTimeMillis': 8,\n",
      " 'nReturned': 6183,\n",
      " 'totalDocsExamined': 6183,\n",
      " 'totalKeysExamined': 6183}\n"
     ]
    }
   ],
   "source": [
    "# Examine the results\n",
    "pprint(collection.find({'cuisine':'American'}).explain()['executionStats'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again:\n",
    "\n",
    "1. we are going over **Only** on the relevant documents in the collection!(\"totalDocsExamined\" = 6183).\n",
    "2. The retuned documents are as we expected('nReturned': 6183).\n",
    "3. 'stage': 'IXSCAN' -  It means that MongoDB has scanned the index key we generated.\n",
    "4. The execution time is 8 miliseconds.\n",
    "5. if \"explain.executionStats.totalKeysExamine\" == \"explain.executionStats.nReturned\" then we achieved maximum efficiency.\n",
    "\n",
    "we save 4 miliseconds! - which sounds like neglectable amount, but we save 33%! and in bigger DB it can make a huge difference.\n",
    "\n",
    "For summary, index creation save us time like jump to the relevant page in a book just by looking at its index.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2 -  capabilities of MongoDB Atlas.\n",
    "\n",
    "* MongoDB Atlas offers full-text search capabilities. Like traditional search indexes(part 1), full-text search indexes help speed up the queries on text fields. [2]\n",
    "* In order to search a text, MongoDB parsing the sentences by \"Analyzer\",  the default \"Analyzer\" is \"Lucene\" (Lucene - is a free and open-source search engine software library and supported by the Apache Software Foundation [3]).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Analyze the results of the \"Standard Analyzer\" of MonogoDb\n",
    "* Most of the examples for textual search suggests use default (\"lucene.standard\").\n",
    "* Standard Analyzer - It divides text into terms based on word boundaries, which makes it language-neutral for most use cases. It converts all terms to lower case and removes punctuation. It provides grammar-based tokenization that recognizes email addresses, acronyms, Chinese-Japanese-Korean characters, alphanumerics, and more[4]\n",
    "\n",
    "Let s create a small collection and investigate it!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# connecting to the collection\n",
    "client = MongoClient(CONN_STRING)\n",
    "mydb = client[DB_NAME]\n",
    "collection = mydb[COLLECTION_NAME]\n",
    "\n",
    "db_creation(collection)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                        _id     title                        message\n0  629f39712df15bd544f09840   fitness       I am going to run, begin\n1  629f39712df15bd544f09841  exercise  they GO to running, beginning\n2  629f39712df15bd544f09842      todo    go go power rangers, begins\n3  629f39712df15bd544f09843  exercise    they go to running, started\n4  629f39712df15bd544f09844    making          went for my beginning\n5  629f39712df15bd544f09845    trying         I am in the 10th place\n6  629f39712df15bd544f09846     place          Again the tenth place",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>title</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>629f39712df15bd544f09840</td>\n      <td>fitness</td>\n      <td>I am going to run, begin</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>629f39712df15bd544f09841</td>\n      <td>exercise</td>\n      <td>they GO to running, beginning</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>629f39712df15bd544f09842</td>\n      <td>todo</td>\n      <td>go go power rangers, begins</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>629f39712df15bd544f09843</td>\n      <td>exercise</td>\n      <td>they go to running, started</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>629f39712df15bd544f09844</td>\n      <td>making</td>\n      <td>went for my beginning</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>629f39712df15bd544f09845</td>\n      <td>trying</td>\n      <td>I am in the 10th place</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>629f39712df15bd544f09846</td>\n      <td>place</td>\n      <td>Again the tenth place</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the collection\n",
    "item_details = collection.find()\n",
    "items_df = pd.DataFrame(item_details)\n",
    "items_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Basic analyzer creation on the \"message\" field"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index not found\n",
      "{'analyzer': 'lucene.standard',\n",
      " 'collectionName': 'sample',\n",
      " 'database': 'test',\n",
      " 'indexID': '629e15b5e1655a375da2177d',\n",
      " 'mappings': {'dynamic': True, 'fields': {'message': {'type': 'string'}}},\n",
      " 'name': 'trying',\n",
      " 'status': 'IN_PROGRESS',\n",
      " 'synonyms': []}\n"
     ]
    }
   ],
   "source": [
    "# If you get \"BAD...\" please wait and run it again!\n",
    "delete_index(CLUSTER_NAME, DB_NAME, COLLECTION_NAME, INDEX_NAME)\n",
    "response = create_index1(CLUSTER_NAME, DB_NAME, COLLECTION_NAME, INDEX_NAME)\n",
    "pprint(response.json())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Let's examine of results, when query  the word \"run\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- Instance:1------------------------\n",
      "**score:** 0.7034\n",
      "**Title:** fitness\n",
      " **Message:** I am going to run, begin\n",
      "> I am going to [[run]], begin\n"
     ]
    }
   ],
   "source": [
    "# run not find word \"running\" only match \"run\"\n",
    "# The double square brackets shows the found word in the query\n",
    "WORD = \"run\"\n",
    "query  = get_query1(WORD)\n",
    "results = list(collection.aggregate(query))\n",
    "display_highlights(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "outputs": [
    {
     "data": {
      "text/plain": "                        _id     title                        message\n0  629df582c7210cdb42fa9910   fitness       I am going to run, begin\n1  629df582c7210cdb42fa9911  exercise  they GO to running, beginning\n3  629df582c7210cdb42fa9913  exercise    they go to running, started",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>title</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>629df582c7210cdb42fa9910</td>\n      <td>fitness</td>\n      <td>I am going to run, begin</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>629df582c7210cdb42fa9911</td>\n      <td>exercise</td>\n      <td>they GO to running, beginning</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>629df582c7210cdb42fa9913</td>\n      <td>exercise</td>\n      <td>they go to running, started</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see that only one instance is returned out of 3 wanted instances(below).\n",
    "items_df.iloc[[0,1,3]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Analyze the results of the \"Custom version 1\" of MonogoDb\n",
    "\n",
    "It is possible to assembly a custom analyzer by stacking different options one upon another[5], here we create a custom analyzer named \"levitas_analyzer\", that does the following:\n",
    "\n",
    "* conversion to ASCII\n",
    "* lowe case\n",
    "* stemming\n",
    "* removal of stopwords(nltk)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# If you get \"BAD...\" please wait and run it again!\n",
    "delete_index(CLUSTER_NAME, DB_NAME, COLLECTION_NAME, INDEX_NAME)\n",
    "response = create_index2(CLUSTER_NAME, DB_NAME, COLLECTION_NAME, INDEX_NAME)\n",
    "pprint(response.json())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1252,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index not found\n",
      "{'analyzer': 'levitas_analyzer',\n",
      " 'analyzers': [{'charFilters': [],\n",
      "                'name': 'levitas_analyzer',\n",
      "                'tokenFilters': [{'type': 'lowercase'},\n",
      "                                 {'stemmerName': 'english',\n",
      "                                  'type': 'snowballStemming'},\n",
      "                                 {'tokens': ['i',\n",
      "                                             'me',\n",
      "                                             'my',\n",
      "                                             'myself',\n",
      "                                             'we',\n",
      "                                             'our',\n",
      "                                             'ours',\n",
      "                                             'ourselves',\n",
      "                                             'you',\n",
      "                                             \"you're\",\n",
      "                                             \"you've\",\n",
      "                                             \"you'll\",\n",
      "                                             \"you'd\",\n",
      "                                             'your',\n",
      "                                             'yours',\n",
      "                                             'yourself',\n",
      "                                             'yourselves',\n",
      "                                             'he',\n",
      "                                             'him',\n",
      "                                             'his',\n",
      "                                             'himself',\n",
      "                                             'she',\n",
      "                                             \"she's\",\n",
      "                                             'her',\n",
      "                                             'hers',\n",
      "                                             'herself',\n",
      "                                             'it',\n",
      "                                             \"it's\",\n",
      "                                             'its',\n",
      "                                             'itself',\n",
      "                                             'they',\n",
      "                                             'them',\n",
      "                                             'their',\n",
      "                                             'theirs',\n",
      "                                             'themselves',\n",
      "                                             'what',\n",
      "                                             'which',\n",
      "                                             'who',\n",
      "                                             'whom',\n",
      "                                             'this',\n",
      "                                             'that',\n",
      "                                             \"that'll\",\n",
      "                                             'these',\n",
      "                                             'those',\n",
      "                                             'am',\n",
      "                                             'is',\n",
      "                                             'are',\n",
      "                                             'was',\n",
      "                                             'were',\n",
      "                                             'be',\n",
      "                                             'been',\n",
      "                                             'being',\n",
      "                                             'have',\n",
      "                                             'has',\n",
      "                                             'had',\n",
      "                                             'having',\n",
      "                                             'do',\n",
      "                                             'does',\n",
      "                                             'did',\n",
      "                                             'doing',\n",
      "                                             'a',\n",
      "                                             'an',\n",
      "                                             'the',\n",
      "                                             'and',\n",
      "                                             'but',\n",
      "                                             'if',\n",
      "                                             'or',\n",
      "                                             'because',\n",
      "                                             'as',\n",
      "                                             'until',\n",
      "                                             'while',\n",
      "                                             'of',\n",
      "                                             'at',\n",
      "                                             'by',\n",
      "                                             'for',\n",
      "                                             'with',\n",
      "                                             'about',\n",
      "                                             'against',\n",
      "                                             'between',\n",
      "                                             'into',\n",
      "                                             'through',\n",
      "                                             'during',\n",
      "                                             'before',\n",
      "                                             'after',\n",
      "                                             'above',\n",
      "                                             'below',\n",
      "                                             'to',\n",
      "                                             'from',\n",
      "                                             'up',\n",
      "                                             'down',\n",
      "                                             'in',\n",
      "                                             'out',\n",
      "                                             'on',\n",
      "                                             'off',\n",
      "                                             'over',\n",
      "                                             'under',\n",
      "                                             'again',\n",
      "                                             'further',\n",
      "                                             'then',\n",
      "                                             'once',\n",
      "                                             'here',\n",
      "                                             'there',\n",
      "                                             'when',\n",
      "                                             'where',\n",
      "                                             'why',\n",
      "                                             'how',\n",
      "                                             'all',\n",
      "                                             'any',\n",
      "                                             'both',\n",
      "                                             'each',\n",
      "                                             'few',\n",
      "                                             'more',\n",
      "                                             'most',\n",
      "                                             'other',\n",
      "                                             'some',\n",
      "                                             'such',\n",
      "                                             'no',\n",
      "                                             'nor',\n",
      "                                             'not',\n",
      "                                             'only',\n",
      "                                             'own',\n",
      "                                             'same',\n",
      "                                             'so',\n",
      "                                             'than',\n",
      "                                             'too',\n",
      "                                             'very',\n",
      "                                             's',\n",
      "                                             't',\n",
      "                                             'can',\n",
      "                                             'will',\n",
      "                                             'just',\n",
      "                                             'don',\n",
      "                                             \"don't\",\n",
      "                                             'should',\n",
      "                                             \"should've\",\n",
      "                                             'now',\n",
      "                                             'd',\n",
      "                                             'll',\n",
      "                                             'm',\n",
      "                                             'o',\n",
      "                                             're',\n",
      "                                             've',\n",
      "                                             'y',\n",
      "                                             'ain',\n",
      "                                             'aren',\n",
      "                                             \"aren't\",\n",
      "                                             'couldn',\n",
      "                                             \"couldn't\",\n",
      "                                             'didn',\n",
      "                                             \"didn't\",\n",
      "                                             'doesn',\n",
      "                                             \"doesn't\",\n",
      "                                             'hadn',\n",
      "                                             \"hadn't\",\n",
      "                                             'hasn',\n",
      "                                             \"hasn't\",\n",
      "                                             'haven',\n",
      "                                             \"haven't\",\n",
      "                                             'isn',\n",
      "                                             \"isn't\",\n",
      "                                             'ma',\n",
      "                                             'mightn',\n",
      "                                             \"mightn't\",\n",
      "                                             'mustn',\n",
      "                                             \"mustn't\",\n",
      "                                             'needn',\n",
      "                                             \"needn't\",\n",
      "                                             'shan',\n",
      "                                             \"shan't\",\n",
      "                                             'shouldn',\n",
      "                                             \"shouldn't\",\n",
      "                                             'wasn',\n",
      "                                             \"wasn't\",\n",
      "                                             'weren',\n",
      "                                             \"weren't\",\n",
      "                                             'won',\n",
      "                                             \"won't\",\n",
      "                                             'wouldn',\n",
      "                                             \"wouldn't\"],\n",
      "                                  'type': 'stopword'}],\n",
      "                'tokenizer': {'type': 'standard'}}],\n",
      " 'collectionName': 'sample',\n",
      " 'database': 'test',\n",
      " 'indexID': '629f352711a8122a200520a3',\n",
      " 'mappings': {'dynamic': True, 'fields': {'message': {'type': 'string'}}},\n",
      " 'name': 'trying',\n",
      " 'searchAnalyzer': 'levitas_analyzer',\n",
      " 'status': 'IN_PROGRESS',\n",
      " 'synonyms': []}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- Instance:1------------------------\n",
      "**score:** 0.3682\n",
      "**Title:** fitness\n",
      " **Message:** I am going to run, begin\n",
      "> I am going to [[run]], begin\n",
      "------------------- Instance:2------------------------\n",
      "**score:** 0.3682\n",
      "**Title:** exercise\n",
      " **Message:** they GO to running, beginning\n",
      "> they GO to [[running]], beginning\n",
      "------------------- Instance:3------------------------\n",
      "**score:** 0.3682\n",
      "**Title:** exercise\n",
      " **Message:** they go to running, started\n",
      "> they go to [[running]], started\n"
     ]
    }
   ],
   "source": [
    "# Now we matches all the \"run\" instances! (it is possible to achieve similar result with \"lucene.english\",but here we have more control)\n",
    "WORD = \"run\"\n",
    "query  = get_query1(WORD)\n",
    "results = list(collection.aggregate(query))\n",
    "display_highlights(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analyze the results of the \"Custom version 2\" of MonogoDb\n",
    "As before including synonyms. In total, it does:\n",
    "\n",
    "* conversion to ASCII\n",
    "* lowe case\n",
    "* stemming\n",
    "* removal of stopwords(nltk)\n",
    "* synonyms\n",
    "\n",
    "In order to make synonyms, we use \"WordNet\" - lexical database of semantic relations between words[6]\n",
    "We search up to 3 most similar words for each given word(using the \"Wu & Palmerâ€™s similarity\")[7] which have more than 90% similarity.\n",
    "Then we inset the synonyms collection to the database[8]."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words are: 147306\n",
      "0.004533334573109945 time in minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": "<pymongo.results.InsertManyResult at 0x2569ac3ed68>"
     },
     "execution_count": 1084,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_synonyms(words_for_syn=None):\n",
    "    terms_dict = {}\n",
    "\n",
    "    ii = 0\n",
    "    if words_for_syn is None:\n",
    "        words_for_syn = [i for i in wn.all_lemma_names()]\n",
    "    print(f\"The number of words fir synonymns are: {len(words_for_syn)}\")\n",
    "\n",
    "    tic = time()\n",
    "    while ii <  NUMBER_OF_SYNONYMS:\n",
    "        word = words_for_syn.pop(0)\n",
    "        if word not in nltk_stop_words:\n",
    "            word_synsets = wn.synsets(word)\n",
    "            single_synonyms = []\n",
    "\n",
    "            for syn in word_synsets:\n",
    "                for l in syn.lemmas():\n",
    "                    examine_word_name = str.replace(l.name(), '-', '_')\n",
    "                    if examine_word_name not in nltk_stop_words and ps.stem(examine_word_name) not in nltk_stop_words:\n",
    "                        single_synonyms.append((examine_word_name, ps.stem(examine_word_name), syn.wup_similarity(word_synsets[0])))\n",
    "\n",
    "            single_synonyms = sorted(single_synonyms, key=lambda x : x[-1], reverse=True)\n",
    "            df = pd.DataFrame(single_synonyms, columns=[\"org\", \"stemmed\", \"similarity\"])\n",
    "            df = df.groupby('stemmed').first()\n",
    "            df = df[df.similarity > SIMILARITY_THRESHOLD]\n",
    "            df = df.sort_values(\"similarity\" , ascending=False).head(NUMBER_OF_RELATIVE_SYNONYMS + 1)\n",
    "            picked_terms = df.index.values.tolist()\n",
    "            # if word in picked_terms:\n",
    "            #     picked_terms.remove(word)\n",
    "            if not((len(picked_terms) == 1) and (word in picked_terms)):\n",
    "                terms_dict[word] = picked_terms\n",
    "            ii +=1\n",
    "\n",
    "    toc = time()\n",
    "    print(f'{(toc - tic)/60} time in minutes')\n",
    "\n",
    "    synonyms_collection_list = []\n",
    "    for term, synonyms_list in terms_dict.items():\n",
    "\n",
    "        synonyms_collection_list.append({\n",
    "                                      \"mappingType\": \"explicit\",\n",
    "                                      \"input\": [term],\n",
    "                                      \"synonyms\": synonyms_list\n",
    "                                    })\n",
    "    return synonyms_collection_list\n",
    "\n",
    "synonyms_collection_list = get_synonyms()\n",
    "\n",
    "synonyms_collection = mydb[SYN_COLLECTION_NAME]\n",
    "synonyms_collection.drop()\n",
    "synonyms_collection.insert_many(synonyms_collection_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index not found\n",
      "{'analyzer': 'levitas_analyzer',\n",
      " 'analyzers': [{'charFilters': [],\n",
      "                'name': 'levitas_analyzer',\n",
      "                'tokenFilters': [{'type': 'asciiFolding'},\n",
      "                                 {'type': 'lowercase'},\n",
      "                                 {'stemmerName': 'english',\n",
      "                                  'type': 'snowballStemming'},\n",
      "                                 {'tokens': ['i',\n",
      "                                             'me',\n",
      "                                             'my',\n",
      "                                             'myself',\n",
      "                                             'we',\n",
      "                                             'our',\n",
      "                                             'ours',\n",
      "                                             'ourselves',\n",
      "                                             'you',\n",
      "                                             \"you're\",\n",
      "                                             \"you've\",\n",
      "                                             \"you'll\",\n",
      "                                             \"you'd\",\n",
      "                                             'your',\n",
      "                                             'yours',\n",
      "                                             'yourself',\n",
      "                                             'yourselves',\n",
      "                                             'he',\n",
      "                                             'him',\n",
      "                                             'his',\n",
      "                                             'himself',\n",
      "                                             'she',\n",
      "                                             \"she's\",\n",
      "                                             'her',\n",
      "                                             'hers',\n",
      "                                             'herself',\n",
      "                                             'it',\n",
      "                                             \"it's\",\n",
      "                                             'its',\n",
      "                                             'itself',\n",
      "                                             'they',\n",
      "                                             'them',\n",
      "                                             'their',\n",
      "                                             'theirs',\n",
      "                                             'themselves',\n",
      "                                             'what',\n",
      "                                             'which',\n",
      "                                             'who',\n",
      "                                             'whom',\n",
      "                                             'this',\n",
      "                                             'that',\n",
      "                                             \"that'll\",\n",
      "                                             'these',\n",
      "                                             'those',\n",
      "                                             'am',\n",
      "                                             'is',\n",
      "                                             'are',\n",
      "                                             'was',\n",
      "                                             'were',\n",
      "                                             'be',\n",
      "                                             'been',\n",
      "                                             'being',\n",
      "                                             'have',\n",
      "                                             'has',\n",
      "                                             'had',\n",
      "                                             'having',\n",
      "                                             'do',\n",
      "                                             'does',\n",
      "                                             'did',\n",
      "                                             'doing',\n",
      "                                             'a',\n",
      "                                             'an',\n",
      "                                             'the',\n",
      "                                             'and',\n",
      "                                             'but',\n",
      "                                             'if',\n",
      "                                             'or',\n",
      "                                             'because',\n",
      "                                             'as',\n",
      "                                             'until',\n",
      "                                             'while',\n",
      "                                             'of',\n",
      "                                             'at',\n",
      "                                             'by',\n",
      "                                             'for',\n",
      "                                             'with',\n",
      "                                             'about',\n",
      "                                             'against',\n",
      "                                             'between',\n",
      "                                             'into',\n",
      "                                             'through',\n",
      "                                             'during',\n",
      "                                             'before',\n",
      "                                             'after',\n",
      "                                             'above',\n",
      "                                             'below',\n",
      "                                             'to',\n",
      "                                             'from',\n",
      "                                             'up',\n",
      "                                             'down',\n",
      "                                             'in',\n",
      "                                             'out',\n",
      "                                             'on',\n",
      "                                             'off',\n",
      "                                             'over',\n",
      "                                             'under',\n",
      "                                             'again',\n",
      "                                             'further',\n",
      "                                             'then',\n",
      "                                             'once',\n",
      "                                             'here',\n",
      "                                             'there',\n",
      "                                             'when',\n",
      "                                             'where',\n",
      "                                             'why',\n",
      "                                             'how',\n",
      "                                             'all',\n",
      "                                             'any',\n",
      "                                             'both',\n",
      "                                             'each',\n",
      "                                             'few',\n",
      "                                             'more',\n",
      "                                             'most',\n",
      "                                             'other',\n",
      "                                             'some',\n",
      "                                             'such',\n",
      "                                             'no',\n",
      "                                             'nor',\n",
      "                                             'not',\n",
      "                                             'only',\n",
      "                                             'own',\n",
      "                                             'same',\n",
      "                                             'so',\n",
      "                                             'than',\n",
      "                                             'too',\n",
      "                                             'very',\n",
      "                                             's',\n",
      "                                             't',\n",
      "                                             'can',\n",
      "                                             'will',\n",
      "                                             'just',\n",
      "                                             'don',\n",
      "                                             \"don't\",\n",
      "                                             'should',\n",
      "                                             \"should've\",\n",
      "                                             'now',\n",
      "                                             'd',\n",
      "                                             'll',\n",
      "                                             'm',\n",
      "                                             'o',\n",
      "                                             're',\n",
      "                                             've',\n",
      "                                             'y',\n",
      "                                             'ain',\n",
      "                                             'aren',\n",
      "                                             \"aren't\",\n",
      "                                             'couldn',\n",
      "                                             \"couldn't\",\n",
      "                                             'didn',\n",
      "                                             \"didn't\",\n",
      "                                             'doesn',\n",
      "                                             \"doesn't\",\n",
      "                                             'hadn',\n",
      "                                             \"hadn't\",\n",
      "                                             'hasn',\n",
      "                                             \"hasn't\",\n",
      "                                             'haven',\n",
      "                                             \"haven't\",\n",
      "                                             'isn',\n",
      "                                             \"isn't\",\n",
      "                                             'ma',\n",
      "                                             'mightn',\n",
      "                                             \"mightn't\",\n",
      "                                             'mustn',\n",
      "                                             \"mustn't\",\n",
      "                                             'needn',\n",
      "                                             \"needn't\",\n",
      "                                             'shan',\n",
      "                                             \"shan't\",\n",
      "                                             'shouldn',\n",
      "                                             \"shouldn't\",\n",
      "                                             'wasn',\n",
      "                                             \"wasn't\",\n",
      "                                             'weren',\n",
      "                                             \"weren't\",\n",
      "                                             'won',\n",
      "                                             \"won't\",\n",
      "                                             'wouldn',\n",
      "                                             \"wouldn't\"],\n",
      "                                  'type': 'stopword'}],\n",
      "                'tokenizer': {'type': 'standard'}}],\n",
      " 'collectionName': 'sample',\n",
      " 'database': 'test',\n",
      " 'indexID': '629e166a17013a18d11396bd',\n",
      " 'mappings': {'dynamic': True, 'fields': {'message': {'type': 'string'}}},\n",
      " 'name': 'trying',\n",
      " 'searchAnalyzer': 'levitas_analyzer',\n",
      " 'status': 'IN_PROGRESS',\n",
      " 'synonyms': [{'analyzer': 'levitas_analyzer',\n",
      "               'name': 'mySynonyms',\n",
      "               'source': {'collection': 'synonyms'}}]}\n"
     ]
    }
   ],
   "source": [
    "# If you get \"BAD...\" please wait and run it again(until the deletion process is finish)!\n",
    "delete_index(CLUSTER_NAME, DB_NAME, COLLECTION_NAME, INDEX_NAME)\n",
    "response = create_index3(CLUSTER_NAME, DB_NAME, COLLECTION_NAME, INDEX_NAME)\n",
    "pprint(response.json())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's examine what we got.\n",
    "In the \"sysnonms\" collection there is the entry:\n",
    "\n",
    "    mappingType: \"explicit\"\n",
    "    input: \"10th\"\n",
    "    synonyms: [\"10th\", \"tenth\"]\n",
    "\n",
    "In the following example without the synonym collection we got only one instance when we search for\"10th\"(\" No synonymns query - try single word\"). In the second example we have two instances(\"Synonymns query - try single word\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                        _id   title                 message\n5  629f39712df15bd544f09845  trying  I am in the 10th place\n6  629f39712df15bd544f09846   place   Again the tenth place",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>title</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>629f39712df15bd544f09845</td>\n      <td>trying</td>\n      <td>I am in the 10th place</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>629f39712df15bd544f09846</td>\n      <td>place</td>\n      <td>Again the tenth place</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instance of the  word and it's synomym\n",
    "items_df.iloc[[5, 6]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- No synonymns query ---------------------------\n",
      "\n",
      "------------------- Instance:1------------------------\n",
      "**score:** 0.8673\n",
      "**Title:** trying\n",
      " **Message:** I am in the 10th place\n",
      "> I am in the [[10th]] place\n",
      "--------------------- Synonymns query ---------------------------\n",
      "\n",
      "------------------- Instance:1------------------------\n",
      "**score:** 0.8673\n",
      "**Title:** trying\n",
      " **Message:** I am in the 10th place\n",
      "> I am in the [[10th]] place\n",
      "------------------- Instance:2------------------------\n",
      "**score:** 0.8673\n",
      "**Title:** place\n",
      " **Message:** Again the tenth place\n",
      "> Again the [[tenth]] place\n"
     ]
    }
   ],
   "source": [
    "WORD = \"10th\"\n",
    "no_syn_query  = get_query1(WORD)\n",
    "no_syn_results = list(collection.aggregate(no_syn_query))\n",
    "\n",
    "syn_query  = get_query2(WORD)\n",
    "syn_results = list(collection.aggregate(syn_query))\n",
    "\n",
    "print(\"---------------------  No synonymns query - try single word ---------------------------\\n\")\n",
    "display_highlights(no_syn_results)\n",
    "\n",
    "print(\"--------------------- Synonymns query - try single word---------------------------\\n\")\n",
    "display_highlights(syn_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "But if we search for a sentence we get nothing!\n",
    "It is because a synonym query ruin the results, it is a known issue[9]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- No synonymns query - try single phrase ---------------------------\n",
      "\n",
      "------------------- Instance:1------------------------\n",
      "**score:** 1.1645\n",
      "**Title:** todo\n",
      " **Message:** go go power rangers, begins\n",
      "> go go [[power]] [[rangers]], begins\n",
      "--------------------- Synonymns query - try single phrase ---------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "WORD = \"The rangers have power\"\n",
    "no_syn_query  = get_query1(WORD)\n",
    "no_syn_results = list(collection.aggregate(no_syn_query))\n",
    "\n",
    "syn_query  = get_query2(WORD)\n",
    "syn_results = list(collection.aggregate(syn_query))\n",
    "\n",
    "print(\"--------------------- No synonymns query - try single phrase ---------------------------\\n\")\n",
    "display_highlights(no_syn_results)\n",
    "\n",
    "print(\"--------------------- Synonymns query - try single phrase ---------------------------\\n\")\n",
    "display_highlights(syn_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can fix it by adding an option for search also without synonym in the same new query"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- synonymns query previous - try single phrase ---------------------------\n",
      "\n",
      "--------------------- Synonymns query new - try single phrase ---------------------------\n",
      "\n",
      "------------------- Instance:1------------------------\n",
      "**score:** 1.1645\n",
      "**Title:** todo\n",
      " **Message:** go go power rangers, begins\n",
      "> go go [[power]] [[rangers]], begins\n"
     ]
    }
   ],
   "source": [
    "WORD = \"The rangers have power\"\n",
    "no_syn_query  = get_query2(WORD)\n",
    "no_syn_results = list(collection.aggregate(no_syn_query))\n",
    "\n",
    "syn_query  = get_query3(WORD)\n",
    "syn_results = list(collection.aggregate(syn_query))\n",
    "\n",
    "print(\"--------------------- synonymns query previous - try single phrase ---------------------------\\n\")\n",
    "display_highlights(no_syn_results)\n",
    "\n",
    "print(\"--------------------- Synonymns query new - try single phrase ---------------------------\\n\")\n",
    "display_highlights(syn_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Part 3 - connect to MongoDB through HTTP\n",
    "The connection bases on[10], with clarifications and the changes needed since it published\n",
    "We are going to use HTTP connection as described in[11]. In order to so that we need\n",
    "1. Private key - Please follow the instructions in [12].\n",
    "2. Public key - we get it from [12] as well.\n",
    "3. GROUP_ID - Groups and projects are synonymous terms. Please go to your \"Projects\"(left side menu) -> on the right side click on the three dots and select \"visit project settings\" -> copy \"Project ID\"\n",
    "4. Create connection string -  Please follow the instructions in [13]."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Resources:\n",
    "[1] ```https://www.analyticsvidhya.com/blog/2020/09/mongodb-indexes-pymongo-tutorial/```\n",
    "[2] ```https://www.mongodb.com/basics/search-index```\n",
    "[3] ```https://en.wikipedia.org/wiki/Apache_Lucene```\n",
    "[4] ```https://www.mongodb.com/docs/atlas/atlas-search/analyzers/standard/#:~:text=The%20standard%20analyzer%20is%20the,lower%20case%20and%20removes%20punctuation.```\n",
    "[5] ```https://www.mongodb.com/docs/atlas/atlas-search/analyzers/custom/#std-label-custom-analyzers```\n",
    "[6] ```https://wordnet.princeton.edu/```\n",
    "[7] ```https://towardsdatascience.com/%EF%B8%8Fwordnet-a-lexical-taxonomy-of-english-words-4373b541cfff#:~:text=WordNet%20is%20a%20large%20lexical,such%20as%20hyponymy%20and%20antonymy.```\n",
    "[8] ```https://www.mongodb.com/docs/atlas/atlas-search/synonyms/```\n",
    "[9] ```https://www.mongodb.com/community/forums/t/synonym-search-not-working-when-searching-for-phrase/144068```\n",
    "[10] ```https://www.youtube.com/watch?v=z-OPkB8fr0U&t=1039s&ab_channel=MongoDB```\n",
    "[11] ```https://www.mongodb.com/docs/atlas/reference/api/fts-indexes-create-one/```\n",
    "[12] ```https://www.mongodb.com/docs/atlas/configure-api-access/```\n",
    "[13] ```https://www.mongodb.com/docs/manual/reference/connection-string/```\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}